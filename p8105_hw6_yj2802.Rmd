---
title: "p8105_hw6_yj2802"
author: "Yizhen Jia"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r}
library(p8105.datasets)
library(tidyverse)
library(modelr)
library(broom)
library(purrr)
library(boot)
library(knitr)
```

## Problem 1

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

This dataset has `r nrow(weather_df)` observations and `r ncol(weather_df)` variables (`r colnames(weather_df)`)

```{r}
# Function for Bootstrap Analysis
bootstrap_analysis = function(data, indices) {
  bootstrap_sample = data[indices, ] # Generate bootstrap sample
  
  # Fit the linear regression model
  bootstrap_fit = lm(tmax ~ tmin, data = bootstrap_sample)
  
  # Extract R-squared
  r_squared = broom::glance(bootstrap_fit)$r.squared
  
  # Extract coefficients and compute log(beta_0 * beta_1)
  coefs = broom::tidy(bootstrap_fit) |>
    filter(term %in% c("(Intercept)", "tmin")) |>
    pull(estimate)
  log_beta_product = log(coefs[1] * coefs[2])
  
  return(c(r_squared = r_squared, log_beta_product = log_beta_product))
}

# Perform Bootstrap Resampling
set.seed(123)
bootstrap_results = boot(
  data = weather_df,
  statistic = function(data, indices) unlist(bootstrap_analysis(data, indices)),
  R = 5000
)

# Create a Data Frame of Bootstrap Results
bootstrap_df = as_tibble(bootstrap_results$t) |>
  rename(r_squared = V1, log_beta_product = V2)

# Plot Distribution of R-squared
r_squared_plot = bootstrap_df |>
  ggplot(aes(x = r_squared)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of R-squared",
    x = "R-squared",
    y = "Density"
  ) +
  theme_minimal()

print(r_squared_plot)

# Plot Distribution of log(beta_0 * beta_1)
log_beta_plot = bootstrap_df |>
  ggplot(aes(x = log_beta_product)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(
    title = "Bootstrap Distribution of log(beta_0 * beta_1)",
    x = "log(beta_0 * beta_1)",
    y = "Density"
  ) +
  theme_minimal()

print(log_beta_plot)

# Compute 95% Confidence Intervals
ci_r_squared = quantile(bootstrap_df$r_squared, probs = c(0.025, 0.975))
ci_log_beta_product = quantile(bootstrap_df$log_beta_product, probs = c(0.025, 0.975))

ci_df = tibble(
  Metric = c("R-squared", "log(beta_0 * beta_1)"),
  `Lower 2.5%` = c(ci_r_squared[1], ci_log_beta_product[1]),
  `Upper 97.5%` = c(ci_r_squared[2], ci_log_beta_product[2])
)

knitr::kable(ci_df, caption = "95% Confidence Intervals for Bootstrap Estimates")

# Final Outputs
ci_r_squared
ci_log_beta_product
```


## Problem 2
```{r}
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicides = read_csv(url)

problem2 = 
  homicides |> 
  mutate(
    across(where(is.character), ~ na_if(., "Unknown")), 
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ 0,
      disposition == "Closed by arrest" ~ 1
    )
  ) |> 
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  ) |> 
  select(city_state, resolution, victim_age, victim_sex, victim_race)
```

#### logistic regression model (Baltimore, MD):

```{r}
baltimore_glm = 
  problem2 |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = _)

baltimore_glm |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(estimate - 1.96 * std.error),
    OR_CI_upper = exp(estimate + 1.96 * std.error)
  ) |> 
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 4)
```

#### logistic regression models for each of the cities:

```{r}
model = 
  problem2 |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, ~ glm(resolution ~ victim_age + victim_sex + victim_race, 
                              family = binomial(), data = .x)),
    tidy_models = map(models, broom::tidy)
  ) |> 
  select(city_state, tidy_models) |> 
  unnest(cols = tidy_models) |> 
  mutate(
    OR = exp(estimate),
    OR_CI_lower = exp(estimate - 1.96 * std.error),
    OR_CI_upper = exp(estimate + 1.96 * std.error)
  ) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

model |> 
  slice(1:5) |> 
  knitr::kable(digits = 4)
```

#### Plot:

```{r}
model |> 
  mutate(city_state = fct_reorder(city_state, OR)) |>
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper), width = 0.2) + 
  labs(
    x = "City, State",
    y = "OR",
    title = "Adjusted Odds Ratios for Solving Homicides",
    subtitle = "Comparing male victims to female victims by city"
  ) + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

This plot shows the adjusted ORs and 95% CIs across cities.

Albuquerque has the highest OR, suggesting potential higher odds of solving male victim cases compared to female victim cases (95% CI includes 1, not significant). Cities such as New York, Baton Rouge and Omaha have ORs and 95% CIs below 1, suggesting male victims are significantly less likely to have cases resolved compared to female victims. Cities with ORs close to 1, such as Tulsa, Atlanta, and Richmond, suggest minimal differences between genders.

## Problem 3

```{r}
birthweight = 
  read_csv("birthweight.csv", na = c("", "NA", "Unknown")) |> 
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")),
    parity = as.numeric(parity),
    smoken = replace_na(smoken, 0),
    wtgain = as.numeric(wtgain)
  ) |> 
  drop_na()
```

#### Model building

```{r}
# Full regression model for birthweight:
model_full = 
  lm(
    bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain,
    data = birthweight
  )

# Remove those are not significant at 0.05 significance level (one by one) to get the final model:
model_final = 
  lm(
    bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken,
    data = birthweight
  )
summary(model_final)
```

The modeling process began by exploring the relationships between birthweight and other variables through summary statistics to identify potential predictors. Firstly, a full regression model was constructed including all available variables hypothesized to influence birthweight. Using a data-driven approach, I iteratively removed variables with the highest p-values (greater than 0.05) one at a time to refine the model. The final model retained only significant predictors, ensuring that all variables had p-values below 0.05. This resulted in a parsimonious model with a Residual Standard Error of 272.3, an Adjusted R-squared of 0.7173, and a highly significant F-statistic (p < 0.0001), indicating strong explanatory power and a good fit for the data.

#### Plot (Residuals vs Fitted Values):

```{r}
birthweight = 
  birthweight |> 
  add_predictions(model_final) |> 
  add_residuals(model_final)

birthweight |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values (Birthweight/grams)",
    y = "Residuals",
    title = "Residuals vs Fitted Values",
    subtitle = "Regression Model for Birthweight"
  ) +
  theme_minimal()
```

#### Comparing models:

```{r}
# Define model formulas
formula_final = bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken
formula_model2 = bwt ~ blength + gaweeks
formula_model3 = bwt ~ bhead * blength * babysex

# Function to calculate mean squared error (MSE)
calculate_mse = function(formula, train, test) {
  train_data = as_tibble(train$data)
  test_data = as_tibble(test$data)
  fitted_model = lm(formula, data = train_data)
  predictions = predict(fitted_model, newdata = test_data)
  mse = mean((test_data$bwt - predictions)^2, na.rm = TRUE)
  return(mse)
}

# Cross-validation setup
set.seed(123)
cv_splits = crossv_mc(birthweight, n = 10)

# Calculate MSE for each model
mse_results = cv_splits |> 
  mutate(
    mse_final = map2_dbl(train, test, ~ calculate_mse(formula_final, .x, .y)),
    mse_model2 = map2_dbl(train, test, ~ calculate_mse(formula_model2, .x, .y)),
    mse_model3 = map2_dbl(train, test, ~ calculate_mse(formula_model3, .x, .y))
  )

# Summarize average MSE for each model
mse_summary = mse_results |> 
  summarize(
    final_model_mse = mean(mse_final),
    model2_mse = mean(mse_model2),
    model3_mse = mean(mse_model3)
  )
mse_summary |>
  knitr::kable(digits = 1)
```

My final model outperforms the other two models in terms of predictive accuracy, as indicated by its lowest cross-validated MSE of 73,925.9. The second model, which uses only birth length and gestational age as predictors, has the highest MSE of 110,957.1, reflecting its simplicity and limited explanatory power. The third model, which includes head circumference, birth length, sex, and all interactions, performs better than the second model with an MSE of 82,638.6, but its added complexity does not surpass the performance of my final model. This demonstrates that the final model strikes a good balance between complexity and predictive accuracy.